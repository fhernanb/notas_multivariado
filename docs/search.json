[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis Multivariado",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html#en-qué-consiste-el-análisis-multivariado",
    "href": "intro.html#en-qué-consiste-el-análisis-multivariado",
    "title": "1  Introducción",
    "section": "1.1 ¿En qué consiste el análisis multivariado?",
    "text": "1.1 ¿En qué consiste el análisis multivariado?\n\n\n\nIlustración"
  },
  {
    "objectID": "intro.html#en-cuáles-situaciones-se-usa-el-análisis-multivariado",
    "href": "intro.html#en-cuáles-situaciones-se-usa-el-análisis-multivariado",
    "title": "1  Introducción",
    "section": "1.2 ¿En cuáles situaciones se usa el análisis multivariado?",
    "text": "1.2 ¿En cuáles situaciones se usa el análisis multivariado?\nLos conceptos de análisis multivariado se usan en muchas áreas, a continuación algunas de ellas con ejemplos ilustrativos.\n\n1.2.1 Mercadeo\nSe estudian seis características acerca de un producto percibidas por un grupo de consumidores, éstas son: calidad del producto, nivel de precio, velocidad de despacho o entrega, servicio, nivel de uso comparado con otros porductos sustitutos, nivel de satisfacción. Se quiere saber acerca de la incidencia, tanto individual como conjunta, de las variables anteriores en la decisión de compra del producto.\n\n\n\nIlustración\n\n\n\n\n1.2.2 Geología\nA lo largo de líneas transversales (en inglés “transects”) toman varias muestras del suelo para estudiar los contenidos (en porcentaje) de arena, azufre, magnesio, arcilla, materia orgánica y pH. También se miden otras variables físicas tales como estructura, humedad, conductividad eléctrica y permeabilidad. El objetivo es determinar las características más relevantes del suelo y hacer una clasificación de éstos.\n\n\n\nIlustración\n\n\n\n\n1.2.3 Arqueología\nSe realizan varias excavaciones en tres regiones donde se tiene la evidencia que habitaron comunidades indígeneas diferentes. Sobre los cráneos conseguidos se midió: la circunferencia, ancho máximo, altura máxima, altura nasal y longitud basialveolar. Esta información permitirá hacer comparaciones entre estas comunidades.\n\n\n\nIlustración"
  },
  {
    "objectID": "intro.html#tipos-de-variables",
    "href": "intro.html#tipos-de-variables",
    "title": "1  Introducción",
    "section": "1.3 Tipos de variables",
    "text": "1.3 Tipos de variables\nEn la siguiente figura se muestran los tipos de variables básicos."
  },
  {
    "objectID": "intro.html#matriz-de-diseño",
    "href": "intro.html#matriz-de-diseño",
    "title": "1  Introducción",
    "section": "1.4 Matriz de diseño",
    "text": "1.4 Matriz de diseño\nLa matriz de diseño se denota por \\(\\boldsymbol{X}\\) y es un arreglo de \\(n\\) filas que representan los objetos o sujetos analizados con \\(p\\) colmunas que representan las variables observadas.\n\n\n\nIlustración"
  },
  {
    "objectID": "intro.html#clasificación-de-los-métodos-multivariados",
    "href": "intro.html#clasificación-de-los-métodos-multivariados",
    "title": "1  Introducción",
    "section": "1.5 Clasificación de los métodos multivariados",
    "text": "1.5 Clasificación de los métodos multivariados\nEn la siguiente figura se presentan los métodos multivariados tradicionales y una clasificación.\n\n\n\nIlustración"
  },
  {
    "objectID": "pca.html#details",
    "href": "pca.html#details",
    "title": "2  Componentes principales",
    "section": "2.1 Details",
    "text": "2.1 Details\n\nSuppose \\([X_{1}, X_{2}, \\dots, X_{p}] = \\boldsymbol{X}^\\top\\) is a set of \\(p\\) random variables, with mean vector \\(\\boldsymbol{\\mu}\\) and variance-covariance matrix \\(\\boldsymbol{\\Sigma}\\). \nWe want to define \\(p\\) linear combinations of \\(\\boldsymbol{X}^\\top\\) that represent the information in \\(\\boldsymbol{X}^\\top\\) more parsimoniously. \nSpecifically, find \\(\\boldsymbol{a}_{1}, \\ldots, \\boldsymbol{a}_{p}\\) such that \\(\\boldsymbol{a}_{1}^\\top \\boldsymbol{X}, \\ldots, \\boldsymbol{a}_{p}^\\top \\boldsymbol{X}\\) gives the same information as \\(\\boldsymbol{X}^\\top\\), but the new random variables, \\(\\boldsymbol{a}_{1}^\\top \\boldsymbol{X}, \\ldots, \\boldsymbol{a}_{p}^\\top \\boldsymbol{X}\\), are ‘nicer’.\nSuppose \\([X_{1}, X_{2}, \\dots, X_{p}] = \\boldsymbol{X}^\\top\\) is a set of \\(p\\) random variables, with mean vector \\(\\boldsymbol{\\mu}\\) and variance-covariance matrix \\(\\boldsymbol{\\Sigma}\\). \nWe want to define \\(p\\) linear combinations of \\(\\boldsymbol{X}^\\top\\) that represent the information in \\(\\boldsymbol{X}^\\top\\) more parsimoniously. \nSpecifically, find \\(\\boldsymbol{a}_{1}, \\ldots, \\boldsymbol{a}_{p}\\) such that \\(\\boldsymbol{a}_{1}^\\top \\boldsymbol{X}, \\ldots, \\boldsymbol{a}_{p}^\\top \\boldsymbol{X}\\) gives the same information as \\(\\boldsymbol{X}^\\top\\), but the new random variables, \\(\\boldsymbol{a}_{1}^\\top \\boldsymbol{X}, \\ldots, \\boldsymbol{a}_{p}^\\top \\boldsymbol{X}\\), are ‘nicer’."
  },
  {
    "objectID": "pca.html#propiedades",
    "href": "pca.html#propiedades",
    "title": "2  Componentes principales",
    "section": "2.2 Propiedades",
    "text": "2.2 Propiedades\n\n\\(Var(\\boldsymbol{a}_{i}^\\top \\boldsymbol{X}) = \\boldsymbol{a}_{i}^\\top \\boldsymbol \\Sigma \\boldsymbol{a}_{i} = \\lambda_{i}\\). \n\\(\\boldsymbol{a}_{i}\\) and \\(\\boldsymbol{a}_{j}\\) are orthogonal, i.e., \\(\\boldsymbol{a}_{i}^\\top \\boldsymbol{a}_{j} = 0\\). \n\\(Cov(\\boldsymbol{a}_{i}^\\top \\boldsymbol{X}, \\boldsymbol{a}_{j}^\\top \\boldsymbol{X}) = \\boldsymbol{a}_{i}^\\top \\boldsymbol \\Sigma \\boldsymbol{a}_{j} = \\boldsymbol{a}_{i}^\\top \\lambda_{j} \\boldsymbol{a}_{j} = \\lambda_{j}\\boldsymbol{a}_{i}^\\top \\boldsymbol{a}_{j} = 0\\). \n\\(Tr(\\boldsymbol \\Sigma) = \\lambda_{1} + \\cdots + \\lambda_{p}\\) = sum of variances for all \\(p\\) principal components, and for \\(X_{1}, \\ldots, X_{p}\\). \nThe importance of the \\(i^{th}\\) principal component is \\(\\lambda_{i}/Tr(\\boldsymbol \\Sigma)\\)."
  },
  {
    "objectID": "pca.html#ejemplo",
    "href": "pca.html#ejemplo",
    "title": "2  Componentes principales",
    "section": "2.3 Ejemplo",
    "text": "2.3 Ejemplo\nSupongamos que tenemos dos variables cuantitativas \\(X_1\\) y \\(X_2\\) como se muestra a continuacion. Queremos encontrar un eje sobre el cual proyectar los puntos de tal manera que las sombras tengan la mayor variabilidad.\n\nmu <- c(0,0)                        # Mean\nSigma <- matrix(c(1, 0.5,\n                  0.5, 1), ncol=2)  # Covariance matrix\n\n# Generate sample from N(mu, Sigma)\nlibrary(MASS)\ndt <- mvrnorm(100, mu=mu, Sigma=Sigma)\nplot(dt, xlab=expression(x[1]), pch=19,\n     ylab=expression(x[2]))\n\n\n\n\nProyectando los puntos sobre los vectores \\((1, 0)^\\top\\), \\((0, 1)^\\top\\) y \\((1/\\sqrt{2}, 1/\\sqrt{2})^\\top\\).\n\npar(mfrow=c(2, 2))\n\nplot(dt, xlab=expression(x[1]), ylab=expression(x[2]), pch=19)\nabline(h=0, col='red', lwd=3)\nabline(v=0, col='aquamarine4', lwd=3)\nabline(a=0, b=1/sqrt(2), col='blue', lwd=3)\n\ny <- dt %*% matrix(c(1, 0), nrow=2)\nplot(density(y), lwd=3, col='red',\n     main=paste('Var=', round(var(y),2)))\nrug(y)\n\ny <- dt %*% matrix(c(0, 1), nrow=2)\nplot(density(y), lwd=3, col='aquamarine4',\n     main=paste('Var=', round(var(y),2)))\nrug(y)\n\ny <- dt %*% matrix(c(1/sqrt(2), 1/sqrt(2)), nrow=2)\nplot(density(y), lwd=3, col='blue',\n     main=paste('Var=', round(var(y),2)))\nrug(y)"
  },
  {
    "objectID": "pca.html#ejemplo-1",
    "href": "pca.html#ejemplo-1",
    "title": "2  Componentes principales",
    "section": "2.4 Ejemplo",
    "text": "2.4 Ejemplo\nA continuacion una base de datos sobre medidas corporales a 36 estudiantes de la universidad el año pasado.\n\nmyurl <- 'https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo'\ndatos <- read.table(file=myurl, header=T, sep='')\nhead(datos)\n\n  edad peso altura   sexo muneca biceps\n1   43 87.3  188.0 Hombre   12.2   35.8\n2   65 80.0  174.0 Hombre   12.0   35.0\n3   45 82.3  176.5 Hombre   11.2   38.5\n4   37 73.6  180.3 Hombre   11.2   32.2\n5   55 74.1  167.6 Hombre   11.8   32.9\n6   33 85.9  188.0 Hombre   12.4   38.5\n\n\nVamos a crear varios diagramas de dispersión para mostrar la relación entre las variables.\n\npairs(datos[, c('peso', 'altura', 'muneca', 'biceps')],\n      pch=19)\n\n\n\n\nVamos a calcular la matriz de varianzas y covarianzas sin incluir la variable sexo.\n\ndt <- datos[, c('peso', 'altura', 'muneca', 'biceps')]\nSigma <- var(dt)\nSigma\n\n            peso     altura    muneca    biceps\npeso   221.08713 124.728698 14.844667 70.738381\naltura 124.72870 110.673968  8.156476 39.021048\nmuneca  14.84467   8.156476  1.381714  5.400571\nbiceps  70.73838  39.021048  5.400571 27.398857\n\nsum(diag(Sigma))\n\n[1] 360.5417\n\n\nEigenvalores e eigenvectores de los datos.\n\nei <- eigen(Sigma)\nei\n\neigen() decomposition\n$values\n[1] 325.1349702  30.8091070   4.3076215   0.2899759\n\n$vectors\n           [,1]        [,2]        [,3]         [,4]\n[1,] 0.81049522  0.47697293  0.33927752  0.022024447\n[2,] 0.52109937 -0.85221951 -0.04660443 -0.002319266\n[3,] 0.05465892  0.04305245 -0.12686657 -0.989476509\n[4,] 0.26184984  0.21063052 -0.93092624  0.142988748\n\nsum(ei$values)\n\n[1] 360.5417\n\n\nEigenvalores e eigenvectores de los datos escalados.\n\ndt.s <- scale(dt)  # Datos escalados\nsum(apply(dt.s, MARGIN=2, FUN=var))\n\n[1] 4\n\nei <- eigen(var(dt.s))\nei\n\neigen() decomposition\n$values\n[1] 3.40781664 0.37981249 0.13515565 0.07721522\n\n$vectors\n           [,1]          [,2]       [,3]       [,4]\n[1,] -0.5229877 -0.0001370885  0.4515021  0.7229313\n[2,] -0.4613002 -0.8346529032 -0.2363538 -0.1862619\n[3,] -0.4985496  0.4607270199 -0.7282171  0.0942266\n[4,] -0.5149118  0.3018031239  0.4582385 -0.6586336\n\nsum(ei$values)\n\n[1] 4\n\n\nPCA usando la funcion princomp de stats.\n\nmod <- prcomp(~ peso + altura + muneca + biceps,\n              data=datos, scale=TRUE)\nmod\n\nStandard deviations (1, .., p=4):\n[1] 1.8460273 0.6162893 0.3676352 0.2778763\n\nRotation (n x k) = (4 x 4):\n              PC1           PC2        PC3        PC4\npeso   -0.5229877  0.0001370885 -0.4515021  0.7229313\naltura -0.4613002  0.8346529032  0.2363538 -0.1862619\nmuneca -0.4985496 -0.4607270199  0.7282171  0.0942266\nbiceps -0.5149118 -0.3018031239 -0.4582385 -0.6586336\n\n\nVamos a crear varios diagramas de dispersión para las variables escaladas.\n\npairs(dt.s[, c('peso', 'altura', 'muneca', 'biceps')],\n      pch=19, col='tomato')\n\n\n\n\nA continuación una tabla de resumen de la aplicación de las componentes principales.\n\nsummary(mod)\n\nImportance of components:\n                          PC1     PC2     PC3    PC4\nStandard deviation     1.8460 0.61629 0.36764 0.2779\nProportion of Variance 0.8519 0.09495 0.03379 0.0193\nCumulative Proportion  0.8519 0.94691 0.98070 1.0000"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2\n\n\nThis is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]